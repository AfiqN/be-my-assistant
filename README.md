# Be My Assistant

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)


**A customizable AI customer service assistant powered by Retrieval Augmented Generation (RAG) and FastAPI.**

This project demonstrates how businesses can leverage their own documents (PDF, DOCX, TXT, MD) to create a context-aware AI assistant capable of answering customer inquiries accurately based on the provided information.

---

### Customer Perspective

![Demo Customer GIF](./assets/Demo%20Customer%20View.gif)

### Admin Perspective

![Demo Admin GIF](./assets/Demo%20Admin%20View.gif)

---

## Key Features

**Admin View:**

* **üìÑ Document Upload:** Easily upload PDF, DOCX, TXT, or MD files containing company information, FAQs, product details, etc.
* **üß† Context Management:** View the list of processed documents providing context to the AI. Delete context from specific files.
* **üé≠ AI Persona Configuration:** Customize the assistant's name, role (e.g., Customer Service, Sales Assistant), personality/tone (e.g., friendly, formal), and company name.
* **üîç Context Testing:** Enter test questions to see which specific text chunks are retrieved from the documents (vector store) and preview the AI's draft answer based *only* on those chunks.

**Customer View:**

* **üí¨ Conversational Interface:** Engage in a natural chat conversation with the AI assistant.
* **üí° Contextual Answers:** Receive answers generated by the AI based *strictly* on the information provided in the uploaded documents.
* **üö´ Fallback Mechanism:** If the information isn't available in the context, the AI will politely state it cannot answer, preventing hallucination.
* **‚ú® Clean UI:** Simple and intuitive chat interface.

---

## Technology Stack

* **Backend:**
  * [![Python](https://img.shields.io/badge/Python-3.13%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
  * [![FastAPI](https://img.shields.io/badge/FastAPI-0.115%2B-green?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
  * [![Uvicorn](https://img.shields.io/badge/Uvicorn-run-purple?logo=python&logoColor=white)](https://www.uvicorn.org/)
  * [![Langchain](https://img.shields.io/badge/LangChain-Core-orange)](https://python.langchain.com/)
* **AI / Machine Learning:**
  * [![Sentence Transformers](https://img.shields.io/badge/Sentence--Transformers-Embeddings-yellow)](https://www.sbert.net/)
  * [![Google Generative AI](https://img.shields.io/badge/Google-Generative%20AI-blue?logo=google&logoColor=white)](https://ai.google.dev/) (Used via LangChain for LLM)
* **Vector Database:**
  * [![ChromaDB](https://img.shields.io/badge/ChromaDB-VectorStore-red)](https://www.trychroma.com/)
* **Frontend:**
  * [![HTML5](https://img.shields.io/badge/HTML5-E34F26?logo=html5&logoColor=white)](https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/HTML5)
  * [![CSS3](https://img.shields.io/badge/CSS3-1572B6?logo=css3&logoColor=white)](https://developer.mozilla.org/en-US/docs/Web/CSS)
  * [![JavaScript](https://img.shields.io/badge/JavaScript-ES6%2B-F7DF1E?logo=javascript&logoColor=black)](https://developer.mozilla.org/en-US/docs/Web/JavaScript)
  * [![Bootstrap](https://img.shields.io/badge/Bootstrap-5.3-7952B3?logo=bootstrap&logoColor=white)](https://getbootstrap.com/)
* **File Processing:**
  * `pypdf`, `python-docx`, `markdown`, `beautifulsoup4`
* **Testing:**
  * [![Pytest](https://img.shields.io/badge/Pytest-testing-blue?logo=pytest&logoColor=white)](https://docs.pytest.org/)

---

## Setup and Installation

1. **Clone the Repository:**

   ```bash
   git clone [https://github.com/AfiqN/be-my-assistant.git](https://github.com/AfiqN/be-my-assistant.git) # Replace with your actual repository URL if different
   cd be-my-assistant
   ```
2. **Create and Activate a Virtual Environment (Recommended):**
   This isolates project dependencies.

   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```
3. **Install Dependencies:**
   Install all required Python packages.

   ```bash
   pip install -r requirements.txt
   ```
4. **Set Up Environment Variables:**

   * Find the `.env.example` file in the project root.
   * **Rename** or **copy** it to a new file named `.env`.
   * **Edit** the `.env` file and **add your Google Generative AI API Key**:
     ```dotenv
     # .env
     # REQUIRED: Get your key from [https://aistudio.google.com/](https://aistudio.google.com/)
     GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
     ```
   * **Important:** The `GOOGLE_API_KEY` is **absolutely required** for the AI chat functionality to work. If it's missing or invalid, the chat endpoint will fail.

---

## Running the Application

1. **Start the FastAPI Server:**
   Make sure your virtual environment is activated.

   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

   * `--reload`: Enables auto-reload when code changes are detected (convenient for development). Remove this for production.
   * `--host 0.0.0.0`: Makes the server accessible from other devices on your network. Use `127.0.0.1` to restrict access to only your local machine.
   * `--port 8000`: Specifies the port the application will run on.
2. **Access the Application:**

   * Open your web browser and navigate to `http://127.0.0.1:8000` (or your server's IP address if running on a network/different host).
3. **API Documentation:**

   * FastAPI automatically generates interactive API documentation (Swagger UI), accessible at `http://127.0.0.1:8000/docs`. You can test API endpoints directly from this interface.
   * Alternative API documentation (ReDoc) is also available at `http://127.0.0.1:8000/redoc`.

---

## Configuration

The application configuration is primarily managed through environment variables loaded from the `.env` file (using `python-dotenv` and `pydantic-settings`). Key variables are defined in `app/config.py`:

* `GOOGLE_API_KEY`: **Mandatory**. Your API key for Google Generative AI models (e.g., Gemini).
* `EMBEDDING_MODEL_NAME`: Specifies the Sentence Transformer model used for creating text embeddings (defaults to `intfloat/multilingual-e5-large`).
* `LLM_MODEL_NAME`: Specifies the Google Generative AI model used for generating chat responses (defaults to `gemini-2.0-flash`).
* `VECTOR_STORE_PATH`: The local directory where the ChromaDB vector database files will be persisted (defaults to `app/data/chroma_db`).
* `VECTOR_COLLECTION_NAME`: The name of the specific collection within ChromaDB where document embeddings are stored (defaults to `documents`).
* `RAG_NUM_RESULTS`: The number of most relevant document chunks to retrieve from the vector store to use as context for the LLM (defaults to 4).
* `RAG_TEMPERATURE`: Controls the creativity/randomness of the LLM's responses. The value is 0.4

Refer to the `.env.example` file for a template and `app/config.py` for default values.

---

## Running Tests

This project includes unit and integration tests using `pytest`. Make sure you have installed the development dependencies (which `pytest` is part of via `requirements.txt`).

From the project root directory (where `README.md` is located), simply run:

```bash
pytest
```

or for more verbose output:

```Bash
pytest -v
```

This command will automatically discover and execute all files starting with `test_` or ending with `_test.py` in the `tests/` directory and its subdirectories.

---

## Future Improvements

* [ ] **Support for More Document Types:** Add parsers for formats like `.pptx`, `.csv`, or even direct web page scraping via URL input.
* [ ] **Asynchronous Processing:** Implement a background task queue (e.g., Celery) for processing large documents to avoid blocking API responses during upload.
* [ ] **User Authentication:** Add a login system for admins to protect context management features.
* [ ] **Chat History Management:** Implement more robust storage and retrieval of chat histories, potentially per-user sessions.
* [ ] **Model Selection UI:** Allow admins to choose different embedding or LLM models through the interface (if multiple are configured/available).
* [ ] **Feedback Mechanism:** Add a way for users (or admins) to rate AI responses to help fine-tune the prompt or identify context gaps.
* [ ] **Deployment:** Add instructions or scripts for deploying the application (e.g., using Docker, serverless platforms).

## License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.

---

## Author & Contact

This project was developed by **Afiq N** as a portfolio piece.

* **GitHub:** [github.com/AfiqN](https://github.com/AfiqN)
* **LinkedIn:** [linkedin.com/in/afiqnur](https://www.linkedin.com/in/afiqnur/)
